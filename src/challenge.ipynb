{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días.\n",
    "\n",
    "## **q1_time.py**\n",
    "\n",
    "## Resultado Tiempo **q1_time.py**\n",
    "```bash\n",
    "py-spy top -- python q1_time.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'       \n",
    "\n",
    "\n",
    "Collecting samples from '\"python\" q1_time.py C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json' (python v3.8.10)\n",
    "Total Samples 1300\n",
    "GIL: 0.00%, Active: 100.00%, Threads: 1\n",
    "\n",
    "  %Own   %Total  OwnTime  TotalTime  Function (filename)\n",
    "  # Se está mostrando sólo la línea del tiempo de ejecución del programa\n",
    " 43.00% 100.00%   0.430s    12.76s   <module> (q1_time.py)\n",
    "```\n",
    "\n",
    "## Resultado Memoria **q1_time.py**\n",
    "```bash\n",
    "python -m memory_profiler q1_time.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'\n",
    "Filename: q1_time.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     7     76.6 MiB     76.6 MiB           1   @profile\n",
    "     8                                         def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "     9                                             # Leer el alrchivo y convertirlo a Dataframe\n",
    "    10   1533.6 MiB   1457.0 MiB           1       df = pd.read_json(file_path, lines=True)\n",
    "    11\n",
    "    12                                             # Se crean/editan los campos necesarios para la consulta\n",
    "    13   1534.8 MiB      1.2 MiB           1       df['date'] = pd.to_datetime(df['date'])\n",
    "    14   1540.2 MiB      5.4 MiB           1       df['date_convert'] = df['date'].dt.date\n",
    "    15   1557.2 MiB     17.0 MiB           1       df['username'] = pd.json_normalize(df['user'])['username']\n",
    "    16\n",
    "    17                                             # tomamos las 10 fechas con mayor cantidad de tweets\n",
    "    18   1557.3 MiB      0.1 MiB           1       top10_dates  = df.groupby(['date_convert']).size().reset_index(name='cant').sort_values(by='cant', ascending=False).head(10)\n",
    "    19\n",
    "    20                                             # para cada una de esas fechas, tomamos los usuarios con mas tweets\n",
    "    21   1557.3 MiB      0.0 MiB           1       results = []\n",
    "    22   1560.9 MiB     -0.8 MiB          11       for top_date in top10_dates['date_convert']:\n",
    "    23   1560.9 MiB      2.8 MiB          10           results.append((top_date, df[df['date_convert'] == top_date].groupby('username').size().reset_index(name='cant').sort_values(by='cant', ascending=False).iloc[0]['username']))\n",
    "    24\n",
    "    25   1560.9 MiB      0.0 MiB           1       return results\n",
    "```\n",
    "\n",
    "## **q1_memory.py**\n",
    "\n",
    "## Resultado Tiempo **q1_memory.py**\n",
    "```bash\n",
    "py-spy top -- python q1_memory.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'     \n",
    "\n",
    "\n",
    "Collecting samples from '\"python\" q1_memory.py C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json' (python v3.8.10)\n",
    "Total Samples 10100\n",
    "GIL: 0.00%, Active: 100.00%, Threads: 1\n",
    "\n",
    "  %Own   %Total  OwnTime  TotalTime  Function (filename)\n",
    "  # Se está mostrando sólo la línea del tiempo de ejecución del programa\n",
    "  0.00% 100.00%    2.10s    99.05s   q1_memory (q1_memory.py)\n",
    "```\n",
    "\n",
    "## Resultado Memoria **q1_memory.py**\n",
    "```bash\n",
    "python -m memory_profiler q1_memory.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'\n",
    "Filename: q1_memory.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     7     76.7 MiB     76.7 MiB           1   @profile\n",
    "     8                                         def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "     9                                             # Leer el alrchivo y convertirlo a Dataframe\n",
    "    10     76.7 MiB      0.0 MiB           1       df = pd.read_json(file_path, lines=True, chunksize=1000)\n",
    "    11     76.7 MiB      0.0 MiB           1       top_dates_aggregated = {}\n",
    "    12\n",
    "    13    112.1 MiB   -186.5 MiB         119       for chunk in df:\n",
    "    14                                                 # Se crean/editan los campos necesarios para la consulta\n",
    "    15    112.1 MiB   -187.2 MiB         118           chunk['date'] = pd.to_datetime(chunk['date'])\n",
    "    16    112.1 MiB   -187.2 MiB         118           chunk['date_convert'] = chunk['date'].dt.date\n",
    "    17    112.1 MiB   -149.1 MiB         118           chunk['username'] = pd.json_normalize(chunk['user'])['username']\n",
    "    18\n",
    "    19                                                 # tomamos las 10 fechas con mayor cantidad de tweets\n",
    "    20    112.1 MiB   -180.2 MiB         118           top10_dates = chunk.groupby(['date_convert']).size().reset_index(name='cant').sort_values(by='cant', ascending=False).head(10)\n",
    "    21                                                 # si ya existe en aggregated, sumar, si no existe, comparar para decidir si se queda o no\n",
    "    22    112.1 MiB   -357.7 MiB         248           for index, row in top10_dates.iterrows():\n",
    "    23    112.1 MiB   -189.0 MiB         130               if row['date_convert'] in top_dates_aggregated:\n",
    "    24    112.1 MiB   -176.9 MiB         117                   top_dates_aggregated[row['date_convert']] += row['cant']\n",
    "    25                                                     else:\n",
    "    26    111.3 MiB    -12.1 MiB          13                   top_dates_aggregated[row['date_convert']] = row['cant']\n",
    "    27\n",
    "    28    103.7 MiB     -8.4 MiB          27       top10_dates_aggregated = sorted(top_dates_aggregated.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "    29\n",
    "    30                                             # para cada una de esas fechas, tomamos los usuarios con mas tweets\n",
    "    31    103.7 MiB      0.0 MiB           1       df = pd.read_json(file_path, lines=True, chunksize=1000)\n",
    "    32    103.7 MiB      0.0 MiB           1       results = {}\n",
    "    33    115.2 MiB   -118.6 MiB         119       for chunk in df:\n",
    "    34    115.2 MiB   -122.4 MiB         118           chunk = chunk.reset_index()\n",
    "    35    115.2 MiB   -122.4 MiB         118           chunk['date'] = pd.to_datetime(chunk['date'])\n",
    "    36    115.2 MiB   -122.4 MiB         118           chunk['date_convert'] = chunk['date'].dt.date\n",
    "    37    115.2 MiB   -117.6 MiB         118           chunk['username'] = pd.json_normalize(chunk['user'])['username']\n",
    "    38    115.2 MiB  -1281.4 MiB        1298           for top_date, _ in top10_dates_aggregated:\n",
    "    39    115.2 MiB  -1164.1 MiB        1180               date_users = chunk[chunk['date_convert'] == top_date].groupby('username').size().reset_index(name='cant').sort_values(by='cant', ascending=False)\n",
    "    40    115.2 MiB  -1164.1 MiB        1180               if top_date in results:\n",
    "    41    115.2 MiB  -1164.1 MiB        1170                   pass\n",
    "    42                                                     else:\n",
    "    43    108.9 MiB      0.0 MiB          10                   results[top_date] = {}\n",
    "    44    115.2 MiB -55181.1 MiB       60057               for _, row in date_users.iterrows():\n",
    "    45    115.2 MiB -56844.7 MiB       58877                   if row['username'] in results[top_date]:\n",
    "    46    115.2 MiB -14552.1 MiB       14718                       results[top_date][row['username']] += row['cant']\n",
    "    47                                                         else:\n",
    "    48    115.2 MiB -39464.7 MiB       44159                       results[top_date][row['username']] = row['cant']\n",
    "    49\n",
    "    50    108.0 MiB     -7.2 MiB           1       results_aggregated = []\n",
    "    51    108.2 MiB      0.0 MiB          11       for top_date, users in results.items():\n",
    "    52    108.2 MiB      0.1 MiB       88328           top_user = sorted(users.items(), key=lambda item: item[1], reverse=True)[:1]\n",
    "    53    108.2 MiB      0.0 MiB          10           results_aggregated.append((top_date, top_user[0][0]))\n",
    "    54\n",
    "    55    108.2 MiB      0.0 MiB           1       return results_aggregated\n",
    "```\n",
    "\n",
    "# 2. Los top 10 emojis más usados con su respectivo conteo.\n",
    "\n",
    "## **q2_time.py**\n",
    "\n",
    "## Resultado Tiempo **q2_time.py**\n",
    "\n",
    "```bash\n",
    "py-spy top -- python q2_time.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'\n",
    "\n",
    "\n",
    "Collecting samples from '\"python\" q2_time.py C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json' (python v3.8.10)\n",
    "Total Samples 2300\n",
    "GIL: 0.00%, Active: 100.00%, Threads: 1\n",
    "\n",
    "  %Own   %Total  OwnTime  TotalTime  Function (filename)\n",
    "  # Se está mostrando sólo la línea del tiempo de ejecución del programa\n",
    "  2.00%  100.00%   0.120s    26.24s   q2_time (q2_time.py)\n",
    "```\n",
    "\n",
    "\n",
    "## Resultado Memoria **q2_time.py**\n",
    "\n",
    "```bash\n",
    "python -m memory_profiler q2_time.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'  \n",
    "Filename: q2_time.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     7     86.6 MiB     86.6 MiB           1   @profile\n",
    "     8                                         def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "     9                                             # Leer el alrchivo y convertirlo a Dataframe\n",
    "    10   1545.7 MiB   1459.1 MiB           1       df = pd.read_json(file_path, lines=True)\n",
    "    11\n",
    "    12                                             # Inicializar un diccionario que se encargará de contar los emoticons dentro del contenido\n",
    "    13   1545.7 MiB      0.0 MiB           1       cont_emojis = {}\n",
    "    14   1546.7 MiB  -8010.2 MiB      117408       for content in df['content']:\n",
    "    15                                                 # Se obtienen los diferentes emojis que se encuentren en el contenido\n",
    "    16   1546.7 MiB  -8009.1 MiB      117407           emojis = emoji.distinct_emoji_list(content)\n",
    "    17                                                 # Se recorren los emojis encontrados\n",
    "    18   1546.7 MiB  -9827.7 MiB      144077           for emoj in emojis:\n",
    "    19                                                     #Se cuenta el array en caso de que ya exista, sino se inicializa en 1\n",
    "    20   1546.7 MiB  -1817.5 MiB       26670               if emoj in cont_emojis:\n",
    "    21   1546.7 MiB  -1776.5 MiB       25800                   cont_emojis[emoj] += 1\n",
    "    22                                                     else:\n",
    "    23   1546.7 MiB    -41.0 MiB         870                   cont_emojis[emoj] = 1\n",
    "    24\n",
    "    25                                             # Convierte el diccionario en un Dataframe\n",
    "    26   1546.7 MiB     -0.1 MiB           1       emojis_df = pd.DataFrame(list(cont_emojis.items()), columns=['Emoji', 'Cant'])\n",
    "    27\n",
    "    28                                             # Se ordena el dataframe por Cantidad de Mayor a Menor y se obtienen los primeros 10\n",
    "    29   1546.8 MiB      0.1 MiB           1       top_emojis = emojis_df.sort_values(by='Cant', ascending=False).head(10)\n",
    "    30\n",
    "    31                                             # Retorna el resultado correspondiente\n",
    "    32   1546.8 MiB      0.0 MiB           1       return top_emojis.values.tolist()\n",
    "```\n",
    "\n",
    "## **q2_memory.py**\n",
    "\n",
    "## Resultado Tiempo **q2_memory.py**\n",
    "\n",
    "```bash\n",
    "py-spy top -- python q2_memory.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'     \n",
    "\n",
    "\n",
    "Collecting samples from '\"python\" q2_memory.py C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json' (python v3.8.10)\n",
    "Total Samples 2900\n",
    "GIL: 0.00%, Active: 100.00%, Threads: 1\n",
    "\n",
    "  %Own   %Total  OwnTime  TotalTime  Function (filename)\n",
    "  # Se está mostrando sólo la línea del tiempo de ejecución del programa\n",
    "  0.00% 100.00%   0.440s    28.40s   q2_memory (q2_memory.py)\n",
    "```\n",
    "\n",
    "## Resultado Memoria **q2_memory.py**\n",
    "\n",
    "```bash\n",
    "python -m memory_profiler q2_memory.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'\n",
    "Filename: q2_memory.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     7     86.6 MiB     86.6 MiB           1   @profile\n",
    "     8                                         def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "     9                                             # Leer el alrchivo y convertirlo a Dataframe\n",
    "    10     86.6 MiB      0.0 MiB           1       df = pd.read_json(file_path, lines=True, chunksize=100)\n",
    "    11\n",
    "    12     86.6 MiB      0.0 MiB           1       cont_emojis = {}\n",
    "    13     95.2 MiB  -1340.6 MiB        1176       for chunk in df:\n",
    "    14     95.2 MiB -135968.7 MiB      118582           for content in chunk['content']:\n",
    "    15                                                     # Se obtienen los diferentes emojis que se encuentren en el contenido\n",
    "    16     95.2 MiB -134619.6 MiB      117407               emojis = emoji.distinct_emoji_list(content)\n",
    "    17                                                     # Se recorren los emojis encontrados\n",
    "    18     95.2 MiB -164654.7 MiB      144077               for emoj in emojis:\n",
    "    19                                                         #Se cuenta el array en caso de que ya exista, sino se inicializa en 1\n",
    "    20     95.2 MiB -30071.0 MiB       26670                   if emoj in cont_emojis:\n",
    "    21     95.2 MiB -29290.6 MiB       25800                       cont_emojis[emoj] += 1\n",
    "    22                                                         else:\n",
    "    23     94.9 MiB   -781.7 MiB         870                       cont_emojis[emoj] = 1\n",
    "    24\n",
    "    25                                             # Convierte el diccionario en un Dataframe\n",
    "    26     93.8 MiB     -1.4 MiB           1       emojis_df = pd.DataFrame(list(cont_emojis.items()), columns=['Emoji', 'Cant'])\n",
    "    27\n",
    "    28                                             # Se ordena el dataframe por Cantidad de Mayor a Menor y se obtienen los primeros 10\n",
    "    29     93.9 MiB      0.0 MiB           1       top_emojis = emojis_df.sort_values(by='Cant', ascending=False).head(10)\n",
    "    30\n",
    "    31                                             # Retorna el resultado correspondiente\n",
    "    32     93.9 MiB      0.0 MiB           1       return top_emojis.values.tolist()\n",
    "```\n",
    "\n",
    "\n",
    "# 3. El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos.\n",
    "\n",
    "## **q3_time.py**\n",
    "\n",
    "## Resultado Tiempo **q3_time.py**\n",
    "\n",
    "```bash\n",
    "py-spy top -- python q3_time.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'                    \n",
    "       \n",
    "\n",
    "Collecting samples from '\"python\" q3_time.py C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json' (python v3.8.10)\n",
    "Total Samples 2300\n",
    "GIL: 0.00%, Active: 100.00%, Threads: 1\n",
    "\n",
    "  %Own   %Total  OwnTime  TotalTime  Function (filename)\n",
    "  # Se está mostrando sólo la línea del tiempo de ejecución del programa\n",
    "  4.00% 100.00%   0.610s    21.78s   q3_time (q3_time.py)\n",
    "```\n",
    "\n",
    "## Resultado Memoria **q3_time.py**\n",
    "\n",
    "```bash\n",
    "python -m memory_profiler q3_time.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'               \n",
    "Filename: q3_time.py                             \n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     6     76.8 MiB     76.8 MiB           1   @profile\n",
    "     7                                         def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "     8                                             # Leer el alrchivo y convertirlo a Dataframe\n",
    "     9   1533.5 MiB   1456.7 MiB           1       df = pd.read_json(file_path, lines=True)\n",
    "    10\n",
    "    11   1533.5 MiB      0.0 MiB           1       lista_usuarios = {}\n",
    "    12   1534.6 MiB      0.0 MiB      117408       for list_users in df['mentionedUsers']:\n",
    "    13   1534.6 MiB      0.0 MiB      117407           if list_users is not None:\n",
    "    14   1534.6 MiB      0.0 MiB      141437               for user in list_users:\n",
    "    15   1534.6 MiB      0.0 MiB      103403                   if user['username'] in lista_usuarios:\n",
    "    16   1534.6 MiB      0.0 MiB       88164                       lista_usuarios[user['username']] += 1\n",
    "    17                                                         else:\n",
    "    18   1534.6 MiB      1.0 MiB       15239                       lista_usuarios[user['username']] = 1\n",
    "    19\n",
    "    20   1534.8 MiB      0.2 MiB       30479       return sorted(lista_usuarios.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "```\n",
    "\n",
    "## **q3_memory.py**\n",
    "\n",
    "## Resultado Tiempo **q3_memory.py**\n",
    "\n",
    "```bash\n",
    "py-spy top -- python q3_memory.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'   \n",
    "\n",
    "\n",
    "Collecting samples from '\"python\" q3_memory.py C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json' (python v3.8.10)\n",
    "Total Samples 7400\n",
    "GIL: 0.00%, Active: 100.00%, Threads: 1\n",
    "\n",
    "  %Own   %Total  OwnTime  TotalTime  Function (filename)\n",
    "  # Se está mostrando sólo la línea del tiempo de ejecución del programa\n",
    "  2.00% 100.00%    1.22s    72.40s   q3_memory (q3_memory.py)\n",
    "```\n",
    "\n",
    "## Resultado Memoria **q3_memory.py**\n",
    "\n",
    "```bash\n",
    "python -m memory_profiler q3_memory.py 'C:\\Users\\indir\\Downloads\\tweets.json\\farmers-protest-tweets-2021-2-4.json'\n",
    "Filename: q3_memory.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "=============================================================\n",
    "     6     76.8 MiB     76.8 MiB           1   @profile\n",
    "     7                                         def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "     8                                             # Leer el alrchivo y convertirlo a Dataframe\n",
    "     9     76.8 MiB      0.1 MiB           1       df = pd.read_json(file_path, lines=True, chunksize=100)\n",
    "    10\n",
    "    11     76.8 MiB      0.0 MiB           1       lista_usuarios = {}\n",
    "    12     86.1 MiB  -1459.6 MiB        1176       for chunk in df:\n",
    "    13     86.1 MiB -148169.0 MiB      118582           for list_users in chunk['mentionedUsers']:\n",
    "    14     86.1 MiB -146701.4 MiB      117407               if list_users is not None:\n",
    "    15     86.1 MiB -177057.3 MiB      141437                   for user in list_users:\n",
    "    16     86.1 MiB -129199.2 MiB      103403                       if user['username'] in lista_usuarios:\n",
    "    17     86.1 MiB -110815.9 MiB       88164                           lista_usuarios[user['username']] += 1\n",
    "    18                                                             else:\n",
    "    19     86.1 MiB -18382.8 MiB       15239                           lista_usuarios[user['username']] = 1\n",
    "    20\n",
    "    21     85.4 MiB     -0.8 MiB       30479       return sorted(lista_usuarios.items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
